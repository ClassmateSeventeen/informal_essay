{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.linear = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, query, key, value):\n",
    "        # query: (batch_size, seq_len_q, input_dim)\n",
    "        # key: (batch_size, seq_len_k, input_dim)\n",
    "        # value: (batch_size, seq_len_v, input_dim)\n",
    "\n",
    "        # 计算注意力权重\n",
    "        scores = torch.matmul(query, key.transpose(1,2))    # (batch_size, seq_len_q, seq_len_k)\n",
    "        attn_weights = self.softmax(scores)                 # (batch_size, seq_len_q, seq_len_k)\n",
    "\n",
    "        # 使用注意力权重加权求和\n",
    "        weighted_values = torch.matmul(attn_weights, value) # (batch_size, seq_len_q, input_dim)\n",
    "\n",
    "        # 应用线性变换\n",
    "        output = self.linear(weighted_values)               # (batch_size, seq_len_q, input_dim)\n",
    "\n",
    "        return output\n",
    "\n",
    "input_dim = 128\n",
    "\n",
    "cross_attention = CrossAttention(input_dim)\n",
    "batch_size = 10\n",
    "seq_len_q = 5\n",
    "seq_len_k = 7\n",
    "seq_len_v = 7\n",
    "\n",
    "query = torch.randn(batch_size, seq_len_q, input_dim)\n",
    "key = torch.randn(batch_size, seq_len_k, input_dim)\n",
    "value = torch.randn(batch_size, seq_len_v, input_dim)\n",
    "\n",
    "\n",
    "# 最后的输出长度大小会和query保持一致\n",
    "output = cross_attention(query, key, value)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 10, 215, 191, 141, 134, 175, 145,  61, 137, 214],\n",
       "        [ 15,  58,  20, 233, 209, 239,  83, 108,  40, 134],\n",
       "        [ 10, 118, 205, 238,  12, 139,  11,  65, 163, 139],\n",
       "        [216, 104,  48,   6,  19, 252,  35, 229, 225,  12],\n",
       "        [135,  94,  78, 140,  95,  37,  89,  78,   6,  83],\n",
       "        [104, 116, 145,  48, 222, 142,  27, 188, 144,  60],\n",
       "        [ 41, 155, 247,  68,  31, 229, 238, 208, 242, 193],\n",
       "        [132,  49, 244, 194, 125, 187,  21, 215,  13, 243],\n",
       "        [ 54, 135,  13, 106, 133, 194, 125,  37, 135, 160],\n",
       "        [216, 152, 174, 199, 111,  67, 175, 246, 157, 177]], dtype=uint8),\n",
       " array([[2.2502748 , 2.74346383, 2.00174007, 2.75396128, 3.60554111,\n",
       "         2.79526385, 1.66875728, 2.52235823, 2.98987255, 2.39911944],\n",
       "        [2.27275922, 3.01173176, 2.18492908, 2.24665088, 3.45180009,\n",
       "         2.89761788, 2.03289828, 3.47495021, 3.06831405, 2.85119874],\n",
       "        [2.76123377, 3.33120267, 2.23834836, 2.37674244, 3.64615766,\n",
       "         2.59872596, 2.06849547, 3.4657516 , 2.97040471, 2.86044941],\n",
       "        [2.54978645, 3.21362314, 2.10774992, 2.25100214, 3.99842138,\n",
       "         2.85689085, 2.02172591, 3.35795674, 3.01458374, 3.17359633],\n",
       "        [1.94907119, 3.15021813, 1.83250539, 2.53060809, 3.08212885,\n",
       "         2.44062956, 1.55774584, 2.37342274, 2.61047571, 2.6937681 ],\n",
       "        [2.15142937, 2.42958758, 1.59729278, 1.64379019, 2.71778705,\n",
       "         1.79302127, 1.40670545, 2.38897602, 2.05548153, 2.1213701 ],\n",
       "        [2.07612857, 2.60614523, 2.10518042, 2.71723832, 3.41974087,\n",
       "         2.88289339, 1.77946686, 2.99194149, 2.76884913, 2.59728868],\n",
       "        [2.66480249, 1.9568449 , 1.85967062, 1.9025467 , 3.50505407,\n",
       "         2.10224286, 2.10914686, 3.39233396, 2.66933531, 2.39933567],\n",
       "        [1.73431197, 2.1088201 , 1.52105631, 1.91693918, 2.57918476,\n",
       "         1.94862429, 1.58773461, 2.28360661, 2.12747724, 2.16560229],\n",
       "        [1.87870977, 2.42887136, 1.80962537, 1.66553598, 2.98479055,\n",
       "         2.47556681, 1.63772803, 2.55961154, 2.5916634 , 2.62171904]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def quantize_to_8int(matrix):\n",
    "    \"\"\"\"简化的量化函数，将矩阵元素量化为8位整数\"\"\"  \n",
    "    min_val = matrix.min()\n",
    "    max_val = matrix.max()\n",
    "    scale = 255 / (max_val - min_val)\n",
    "    quantized = np.round(scale * (matrix - min_val)).astype(np.uint8)\n",
    "    return quantized\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"矩阵乘法, 使用8位整数量化\"\"\"\n",
    "    A_quantized = quantize_to_8int(A)\n",
    "    B_quantized = quantize_to_8int(B)\n",
    "    return np.matmul(A_quantized, B_quantized)\n",
    "\n",
    "# 测试矩阵乘法\n",
    "A = np.random.rand(10, 10)\n",
    "B = np.random.rand(10, 10)\n",
    "# 执行8位量化矩阵乘法\n",
    "result_float = np.matmul(A, B)\n",
    "result = matrix_multiply(A, B)\n",
    "result, result_float"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
